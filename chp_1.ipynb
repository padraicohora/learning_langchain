{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e07e781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "qgenie_api_key = os.getenv(\"QGENIE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2570552",
   "metadata": {},
   "source": [
    "Using LLMs in LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd5bcfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "blue.\n"
     ]
    }
   ],
   "source": [
    "from qgenie import QGenieClient, ChatMessage\n",
    "client = QGenieClient(endpoint=\"https://qgenie-chat.qualcomm.com\", api_key=qgenie_api_key )\n",
    "\n",
    "chat_response = client.chat(\n",
    "    messages=[ChatMessage(role=\"user\", content=\"The sky is\")],\n",
    "    max_tokens=400,\n",
    ")\n",
    "\n",
    "print(chat_response.first_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3db5df9",
   "metadata": {},
   "source": [
    "Roles example:\n",
    "\n",
    "System role\n",
    "Used for instructions the model should use to answer a user question\n",
    "\n",
    "User role\n",
    "Used for the user’s query and any other content produced by the user\n",
    "\n",
    "Assistant role\n",
    "Used for content generated by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f95a3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n\\nThe capital of France is Paris.', additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 22, 'total_tokens': 31, 'completion_tokens': 9}, 'model': 'Turbo', 'finish_reason': 'FinishReason.stop'}, id='run--e37cea81-6116-40c3-beee-813db048ea49-0', usage_metadata={'input_tokens': 22, 'output_tokens': 9, 'total_tokens': 31})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from qgenie.integrations.langchain import QGenieChat\n",
    "\n",
    "model = QGenieChat(model=\"Turbo\")\n",
    "prompt = [HumanMessage(\"What is the capital of France?\")]\n",
    "\n",
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae757b9",
   "metadata": {},
   "source": [
    "Different chat messages\n",
    "\n",
    "HumanMessage\n",
    "A message sent from the perspective of the human, with the user role\n",
    "\n",
    "AIMessage\n",
    "A message sent from the perspective of the AI that the human is interacting with, with the assistant role\n",
    "\n",
    "SystemMessage\n",
    "A message setting the instructions the AI should follow, with the system role\n",
    "\n",
    "ChatMessage\n",
    "A message allowing for arbitrary setting of role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ac73eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n\\nThe capital of France is Paris!!!', additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 37, 'total_tokens': 46, 'completion_tokens': 9}, 'model': 'Turbo', 'finish_reason': 'FinishReason.stop'}, id='run--f61d68c8-0361-41c3-a889-d442dfd010af-0', usage_metadata={'input_tokens': 37, 'output_tokens': 9, 'total_tokens': 46})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "system_msg = SystemMessage(\n",
    "    'You are a helpful assistant that responds to questions with three exclamation marks'\n",
    ")\n",
    "\n",
    "human_msg = HumanMessage(\"what is the capital of France?\")\n",
    "\n",
    "model.invoke([system_msg, human_msg])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6891282f",
   "metadata": {},
   "source": [
    "Making LLM Prompts Reusable using prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "052d88d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = '''\n",
    "Answer the question based on the context below. If the question cannot be\n",
    "answered using the information provided, answer with \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    " '''\n",
    "\n",
    "template = PromptTemplate.from_template(template)\n",
    "\n",
    "prompt = template.invoke({\n",
    "    \"context\": '''\n",
    "        The most recent advancements in NLP are being driven by Large \n",
    "        Language Models (LLMs). These models outperform their smaller \n",
    "        counterparts and have become invaluable for developers who are creating \n",
    "        applications with NLP capabilities. Developers can tap into these \n",
    "        models through Hugging Face's `transformers` library, or by utilizing \n",
    "        OpenAI and Cohere's offerings through the `openai` and `cohere` \n",
    "        libraries, respectively.\n",
    "    ''',\n",
    "\"question\": ''' \n",
    "        Which model providers offer LLMs?\n",
    "    '''\n",
    "})\n",
    "\n",
    "completion = model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2978f75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n\\nHugging Face, OpenAI, and Cohere offer LLMs.', additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 158, 'total_tokens': 175, 'completion_tokens': 17}, 'model': 'Turbo', 'finish_reason': 'FinishReason.stop'}, id='run--8e5fad74-eb59-4bf3-b87c-fb249bcfeb0e-0', usage_metadata={'input_tokens': 158, 'output_tokens': 17, 'total_tokens': 175})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e441e418",
   "metadata": {},
   "source": [
    "Using a role base chat prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23e33c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n\\nHugging Face, OpenAI, and Cohere offer LLMs.', additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 153, 'total_tokens': 170, 'completion_tokens': 17}, 'model': 'Turbo', 'finish_reason': 'FinishReason.stop'}, id='run--656d987b-ce69-499d-9577-74c6cd7a1082-0', usage_metadata={'input_tokens': 153, 'output_tokens': 17, 'total_tokens': 170})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    ('system', ''' Answer the question based on the context below. If the \n",
    "        question cannot be answered using the information provided, answer with \n",
    "        \"I don\\'t know\".''' ),\n",
    "    ('human', 'Context: {context}'),\n",
    "    ('human', 'Context: {question}'),\n",
    "])\n",
    "\n",
    "prompt = template.invoke({\n",
    "    \"context\": ''' The most recent advancements in NLP are being driven by Large \n",
    "        Language Models (LLMs). These models outperform their smaller \n",
    "        counterparts and have become invaluable for developers who are creating \n",
    "        applications with NLP capabilities. Developers can tap into these \n",
    "        models through Hugging Face's `transformers` library, or by utilizing \n",
    "        OpenAI and Cohere's offerings through the `openai` and `cohere` \n",
    "        libraries, respectively. ''', \n",
    "    \"question\": \"Which model providers offer LLMs?\"\n",
    "})\n",
    "\n",
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e189bc",
   "metadata": {},
   "source": [
    "Getting Specific Formats out of LLMs such as JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "958b0b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnswerWithJustificstion(answer='They weigh the same', justification='A pound is a unit of weight or mass, so one pound of bricks and one pound of feathers both weigh the same amount, one pound.')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "\n",
    "class AnswerWithJustificstion(BaseModel):\n",
    "    '''An answer to the user's question along with justification for the \n",
    "        answer.'''\n",
    "    answer: str\n",
    "    '''The Answer to the user's question'''\n",
    "    justification: str\n",
    "    '''Justification for the answer'''\n",
    "\n",
    "llm = QGenieChat(model=\"Pro\", max_tokens=512)\n",
    "\n",
    "structured_llm = llm.with_structured_output(AnswerWithJustificstion)\n",
    "\n",
    "structured_llm.invoke('''What weighs more, a pound of bricks or a pound \n",
    "    of feathers ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ce1f8c",
   "metadata": {},
   "source": [
    "Other Machine-Readable Formats with Output Parsers\n",
    "\n",
    "Output parsers are classes that help you structure large language model responses. They serve two functions:\n",
    "\n",
    "Providing format instructions\n",
    "Output parsers can be used to inject some additional instructions in the prompt that will help guide the LLM to output text in the format it knows how to parse.\n",
    "\n",
    "Validating and parsing output\n",
    "The main function is to take the textual output of the LLM or chat model and render it to a more structured format, such as a list, XML, or other format. This can include removing extraneous information, correcting incomplete output, and validating the parsed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67bc260d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'banana', 'cherry']\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "items = parser.invoke(\"apple, banana, cherry\")\n",
    "\n",
    "print(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339b9860",
   "metadata": {},
   "source": [
    "Assembling the Many Pieces of an LLM Application\n",
    "\n",
    "Using the Runnable Interface:\n",
    "\n",
    "- There is a common interface with these methods:\n",
    "\n",
    "    - invoke: transforms a single input into an output. Takes a single input and returns a single output.\n",
    "    - batch: efficiently transforms multiple inputs into multiple outputs. takes a list of outputs and returns a list of outputs.\n",
    "    - stream: streams output from a single input as it’s produced. takes a single input and returns an iterator of parts of the output as they become available.\n",
    "- There are built-in utilities for retries, fallbacks, schemas, and runtime configurability.\n",
    "- In Python, each of the three methods have asyncio equivalents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "762e8487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "It's nice to meet you. Is there something I can help you with or would you like to chat?\n"
     ]
    }
   ],
   "source": [
    "completion = model.invoke(\"Hi there!\")\n",
    "print(completion.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73385ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "It's nice to meet you. Is there something I can help you with or would you like to chat?\n",
      "\n",
      "\n",
      "Bye! It was nice chatting with you. If you ever need anything or just want to chat, feel free to come back anytime. Have a great day!\n"
     ]
    }
   ],
   "source": [
    "completions = model.batch([\"Hi there!\", \"Bye!\"])\n",
    "completions\n",
    "\n",
    "for c in completions:\n",
    "    print(c.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80afebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "By\n",
      "e! It\n",
      " was nice\n",
      " chatting with\n",
      " you\n",
      ". If\n",
      " you ever\n",
      " need anything or\n",
      " just want to\n",
      " chat\n",
      ", feel free to come\n",
      " back\n",
      " anytime.\n",
      " Have a great\n",
      " day!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for token in model.stream(\"Bye!\"):\n",
    "    print(token.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40d3a6b",
   "metadata": {},
   "source": [
    "Imperative Composition\n",
    "Imperative composition is just a fancy name for writing the code you’re used to writing, composing these components into functions and classes. Here’s an example combining prompts, models, and output parsers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f626c1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"\\n\\nHere are some of the top car manufacturers that offer high-performing hybrid cars:\\n\\n1. **Toyota**: Known for their Prius, Toyota offers a range of hybrid models, including the Prius Prime, Camry Hybrid, and RAV4 Hybrid. Their hybrids are known for their fuel efficiency and reliability.\\n2. **Honda**: Honda's hybrid lineup includes the Insight, CR-V Hybrid, and Accord Hybrid. Their hybrids are praised for their smooth acceleration and excellent fuel economy.\\n3. **Hyundai**: Hyundai's hybrid models, such as the Ioniq Hybrid and Kona Hybrid, offer impressive fuel efficiency and a range of features, including a comfortable ride and advanced safety features.\\n4. **Ford**: Ford's hybrid lineup includes the Fusion Hybrid, Escape Hybrid, and Explorer Hybrid. Their hybrids are known for their performance and innovative features, such as the ability to switch between electric and gasoline power.\\n5. **Lexus**: As a luxury brand, Lexus offers high-performance hybrids like the ES Hybrid, GS Hybrid, and RX Hybrid. Their hybrids are known for their smooth ride, luxurious interior, and impressive fuel efficiency.\\n6. **Audi**: Audi's hybrid models, such as the A3 Sportback e-tron and Q5 TFSI e, offer a blend of performance and efficiency. Their hybrids are known for their advanced technology and sleek design.\\n7. **BMW**: BMW's hybrid lineup includes the X5 xDrive45e and 330e, which offer a balance of performance and fuel efficiency. Their hybrids are known for their handling and advanced features.\\n8. **Mercedes-Benz**: Mercedes-Benz's hybrid models, such as the S 560e and E 350e, offer a luxurious driving experience and impressive fuel efficiency. Their hybrids are known for their advanced technology and comfort.\\n9. **Kia**: Kia's hybrid models, such as the Niro Hybrid and Optima Hybrid, offer a range of features, including a comfortable ride and advanced safety features.\\n10. **Subaru**: Subaru's hybrid models, such as the Crosstrek Hybrid and Ascent Hybrid, offer all-wheel drive and impressive fuel efficiency. Their hybrids are known for their reliability and off-road capability.\\n\\nSome of the top hybrid models in each category are:\\n\\n**Best Hybrid Sedans:**\\n\\n* Toyota Prius Prime\\n* Honda Insight\\n* Hyundai Ioniq Hybrid\\n* Ford Fusion Hybrid\\n* Lexus ES Hybrid\\n\\n**Best Hybrid SUVs:**\\n\\n* Toyota RAV4 Hybrid\\n* Honda CR-V Hybrid\\n* Hyundai Kona Hybrid\\n* Ford Escape Hybrid\\n* Subaru Crosstrek Hybrid\\n\\n**Best Hybrid Luxury Cars:**\\n\\n* Lexus ES Hybrid\\n* Audi A3 Sportback e-tron\\n* BMW 330e\\n* Mercedes-Benz S 560e\\n* Audi Q5 TFSI e\\n\\nNote: This is not an exhaustive list, and there are many other great hybrid models available in the market. The best hybrid car for you will depend on your specific needs and preferences.\", additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 32, 'total_tokens': 646, 'completion_tokens': 614}, 'model': 'Turbo', 'finish_reason': 'FinishReason.stop'}, id='run--b0583990-61c8-4c87-bc4a-771a729745dc-0', usage_metadata={'input_tokens': 32, 'output_tokens': 614, 'total_tokens': 646})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import chain\n",
    "\n",
    "# the building blocks\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'You are a hlepful assistant'),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "# combine them in a function\n",
    "# @chain decorator adds the same Runnable interface for any function you write\n",
    "\n",
    "@chain\n",
    "def chatbot(values):\n",
    "    prompt = template.invoke(values)\n",
    "    return model.invoke(prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef2cc0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Here are some of the top car manufacturers that offer high-performing hybrid cars:\n",
      "\n",
      "1. **Toyota**: Known for their Prius, Toyota offers a range of hybrid models, including the Prius Prime, Camry Hybrid, and RAV4 Hybrid. Their hybrids are known for their fuel efficiency and reliability.\n",
      "2. **Honda**: Honda's hybrid lineup includes the Insight, CR-V Hybrid, and Accord Hybrid. Their hybrids are praised for their smooth acceleration and excellent fuel economy.\n",
      "3. **Hyundai**: Hyundai's hybrid models, such as the Ioniq Hybrid and Kona Hybrid, offer impressive fuel efficiency and a range of features like adaptive cruise control and lane departure warning.\n",
      "4. **Ford**: Ford's hybrid lineup includes the Fusion Hybrid, Escape Hybrid, and Explorer Hybrid. Their hybrids are known for their sporty performance and advanced technology features.\n",
      "5. **Lexus**: As a luxury brand, Lexus offers high-performance hybrids like the ES Hybrid, GS Hybrid, and RX Hybrid. Their hybrids are known for their smooth ride and luxurious interior.\n",
      "6. **Audi**: Audi's hybrid models, such as the A3 Sportback e-tron and Q5 TFSI e, offer impressive performance and advanced technology features like adaptive cruise control and lane departure warning.\n",
      "7. **BMW**: BMW's hybrid lineup includes the X5 xDrive45e and 330e, which offer impressive performance and advanced features like adaptive cruise control and a heads-up display.\n",
      "8. **Mercedes-Benz**: Mercedes-Benz offers a range of hybrid models, including the S-Class Hybrid, E-Class Hybrid, and GLE Hybrid. Their hybrids are known for their luxurious interior and advanced safety features.\n",
      "9. **Kia**: Kia's hybrid models, such as the Niro Hybrid and Optima Hybrid, offer impressive fuel efficiency and a range of features like adaptive cruise control and lane departure warning.\n",
      "10. **Subaru**: Subaru's hybrid models, such as the Crosstrek Hybrid and Outback Hybrid, offer impressive all-wheel drive capability and excellent fuel economy.\n",
      "\n",
      "Some of the top hybrid models in each category are:\n",
      "\n",
      "**Best Hybrid Sedans:**\n",
      "\n",
      "* Toyota Prius Prime\n",
      "* Honda Insight\n",
      "* Hyundai Ioniq Hybrid\n",
      "* Ford Fusion Hybrid\n",
      "* Lexus ES Hybrid\n",
      "\n",
      "**Best Hybrid SUVs:**\n",
      "\n",
      "* Toyota RAV4 Hybrid\n",
      "* Honda CR-V Hybrid\n",
      "* Hyundai Kona Hybrid\n",
      "* Ford Escape Hybrid\n",
      "* Subaru Crosstrek Hybrid\n",
      "\n",
      "**Best Hybrid Luxury Cars:**\n",
      "\n",
      "* Lexus ES Hybrid\n",
      "* Audi A3 Sportback e-tron\n",
      "* BMW 330e\n",
      "* Mercedes-Benz S-Class Hybrid\n",
      "* Audi Q5 TFSI e\n",
      "\n",
      "Note: This is not an exhaustive list, and there are many other great hybrid models available in the market. The best hybrid car for you will depend on your specific needs and preferences.\n"
     ]
    }
   ],
   "source": [
    "# use it\n",
    "print(chatbot.invoke({\"question\": \"What car manufacturers see the best performing hybrid cars?\"}).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4f634b",
   "metadata": {},
   "source": [
    "A streamable version of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a8c65c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Several\n",
      " model\n",
      " providers offer Large Language\n",
      " Models (LLMs\n",
      "). Here are some of the\n",
      " most notable\n",
      " ones:\n",
      "\n",
      "1. **H\n",
      "ugging Face\n",
      " Transformers\n",
      "**: Hugging Face offers\n",
      " a wide\n",
      " range of pre\n",
      "-trained L\n",
      "LMs, including B\n",
      "ERT\n",
      ", RoBERTa\n",
      ", DistilBERT\n",
      ", and many\n",
      " others\n",
      ",\n",
      " through their Transformers\n",
      " library.\n",
      "2. **Google\n",
      " Cloud\n",
      " AI\n",
      " Platform\n",
      "**: Google Cloud offers\n",
      " a range\n",
      " of L\n",
      "LMs, including B\n",
      "ERT, Ro\n",
      "BERTa, and AL\n",
      "BERT\n",
      ", through their AI\n",
      " Platform.\n",
      "3. **Microsoft\n",
      " Azure Cognitive\n",
      " Services\n",
      "**: Microsoft Azure offers\n",
      " a range of LLMs\n",
      ", including B\n",
      "ERT, RoBERTa,\n",
      " and Turing\n",
      "-N\n",
      "LG\n",
      ", through their Cognitive\n",
      " Services.\n",
      "4. **IBM\n",
      " Watson Studio\n",
      "**: IBM Watson Studio\n",
      " offers a range of LLM\n",
      "s, including B\n",
      "ERT, Ro\n",
      "BERTa, and U\n",
      "LM\n",
      "Fi\n",
      "T\n",
      ", through their Watson\n",
      " Studio platform\n",
      ".\n",
      "5. **Amazon Sage\n",
      "Maker\n",
      "**: Amazon SageMaker offers a\n",
      " range of LLMs,\n",
      " including BERT, RoBERT\n",
      "a, and Dist\n",
      "ilBERT, through their Sage\n",
      "Maker platform.\n",
      "6. **\n",
      "Deep\n",
      "Mind\n",
      "**: DeepMind,\n",
      " a subsidiary\n",
      " of Alphabet\n",
      " Inc\n",
      ".,\n",
      " offers a range of LLM\n",
      "s, including Alpha\n",
      "BERT\n",
      " and\n",
      " Alpha\n",
      "Ro\n",
      "BERTa, through their Deep\n",
      "Mind platform.\n",
      "7. **\n",
      "Meta\n",
      " AI\n",
      "**: Meta AI offers\n",
      " a range of LLMs\n",
      ", including BERT, Ro\n",
      "BERTa, and XL\n",
      "Net\n",
      ", through their Meta\n",
      " AI\n",
      " platform.\n",
      "8. **Stan\n",
      "ford\n",
      " Natural\n",
      " Language Processing\n",
      " Group\n",
      "**: The\n",
      " Stanford N\n",
      "LP Group offers a range of\n",
      " LLMs, including B\n",
      "ERT, RoBERTa,\n",
      " and XL\n",
      "Net, through their GitHub\n",
      " repository.\n",
      "9. **Facebook\n",
      " AI**: Facebook AI offers a\n",
      " range of LLMs,\n",
      " including BERT, RoBERT\n",
      "a, and XLNet,\n",
      " through their Facebook AI\n",
      " platform.\n",
      "10. **Open\n",
      "AI\n",
      "**: OpenAI offers a range\n",
      " of LLMs\n",
      ", including GPT-\n",
      "3\n",
      ", through\n",
      " their Open\n",
      "AI platform.\n",
      "\n",
      "These are just\n",
      " a few examples\n",
      " of model\n",
      " providers that offer LLMs\n",
      ". There are many\n",
      " other providers\n",
      " and researchers\n",
      " who\n",
      " offer\n",
      " their\n",
      " own\n",
      " LLMs,\n",
      " and\n",
      " the landscape\n",
      " is\n",
      " constantly evolving.\n",
      "\n",
      "\n",
      "It's worth\n",
      " noting\n",
      " that some of these\n",
      " providers\n",
      " may offer\n",
      " their\n",
      " L\n",
      "LMs as\n",
      " part\n",
      " of a\n",
      " larger platform or service, while\n",
      " others may offer\n",
      " them\n",
      " as standalone models\n",
      " that\n",
      " can\n",
      " be fine\n",
      "-t\n",
      "uned or\n",
      " customized\n",
      " by\n",
      " users\n",
      ".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@chain\n",
    "def chatbot(values):\n",
    "    prompt = template.invoke(values)\n",
    "    for token in model.stream(prompt):\n",
    "        yield token\n",
    "\n",
    "for part in chatbot.stream({\n",
    "    \"question\": \"Which model providers offer LLMs?\"\n",
    "}):\n",
    "    print(part.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfa0dd3",
   "metadata": {},
   "source": [
    "Async verison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d007f99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"\\n\\nSeveral model providers offer Large Language Models (LLMs). Here are some of the most notable ones:\\n\\n1. **Hugging Face Transformers**: Hugging Face offers a wide range of pre-trained LLMs, including BERT, RoBERTa, DistilBERT, and many others, through their Transformers library.\\n2. **Google Cloud AI Platform**: Google Cloud offers a range of LLMs, including BERT, RoBERTa, and XLNet, through their AI Platform.\\n3. **Microsoft Azure Cognitive Services**: Microsoft Azure offers a range of LLMs, including BERT, RoBERTa, and Turing-NLG, through their Cognitive Services.\\n4. **Amazon SageMaker**: Amazon SageMaker offers a range of LLMs, including BERT, RoBERTa, and XLNet, through their SageMaker platform.\\n5. **IBM Watson**: IBM Watson offers a range of LLMs, including BERT, RoBERTa, and ULMFiT, through their Watson platform.\\n6. **DeepMind**: DeepMind, a subsidiary of Alphabet Inc., offers a range of LLMs, including AlphaFold and AlphaGo, through their DeepMind platform.\\n7. **Meta AI**: Meta AI offers a range of LLMs, including BERT, RoBERTa, and XLNet, through their AI platform.\\n8. **Stanford Natural Language Processing Group**: The Stanford NLP Group offers a range of LLMs, including BERT, RoBERTa, and XLNet, through their GitHub repository.\\n9. **Allen Institute for Artificial Intelligence (AI2)**: AI2 offers a range of LLMs, including BERT, RoBERTa, and ULMFiT, through their GitHub repository.\\n10. **OpenAI**: OpenAI offers a range of LLMs, including GPT-3, through their API.\\n\\nThese are just a few examples of model providers that offer LLMs. There are many other organizations and researchers that also offer LLMs, and the list is constantly growing.\\n\\nIt's worth noting that some of these providers may offer pre-trained models, while others may offer fine-tuned models or allow you to train your own LLMs from scratch. Additionally, some providers may offer APIs or SDKs to integrate their LLMs into your applications.\", additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 30, 'total_tokens': 506, 'completion_tokens': 476}, 'model': 'Turbo', 'finish_reason': 'FinishReason.stop'}, id='run--055e9556-3bf2-4074-bd2d-2b52a623c9c8-0', usage_metadata={'input_tokens': 30, 'output_tokens': 476, 'total_tokens': 506})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@chain\n",
    "async def chatbot(values):\n",
    "    prompt = await template.ainvoke(values)\n",
    "    return await model.ainvoke(prompt)\n",
    "\n",
    "await chatbot.ainvoke({\"question\": \"Which model providers offer LLMs?\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afdd2f4",
   "metadata": {},
   "source": [
    "Declarative Composition\n",
    "\n",
    "LCEL is a declarative language for composing LangChain components. LangChain compiles LCEL compositions to an optimized execution plan, with automatic parallelization, streaming, tracing, and async support.\n",
    "\n",
    "Let’s see the same example using LCEL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f27afc76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n\\nSeveral model providers offer Large Language Models (LLMs). Here are some of the most well-known ones:\\n\\n1. **Hugging Face Transformers**: Hugging Face offers a wide range of pre-trained LLMs, including BERT, RoBERTa, DistilBERT, and many others, through their Transformers library.\\n2. **Google Cloud AI Platform**: Google Cloud offers a range of LLMs, including BERT, RoBERTa, and ALBERT, through their AI Platform.\\n3. **Microsoft Azure Cognitive Services**: Microsoft Azure offers a range of LLMs, including BERT, RoBERTa, and Turing-NLG, through their Cognitive Services.\\n4. **IBM Watson**: IBM Watson offers a range of LLMs, including BERT, RoBERTa, and ULMFiT, through their Watson Assistant.\\n5. **Amazon SageMaker**: Amazon SageMaker offers a range of LLMs, including BERT, RoBERTa, and XLNet, through their SageMaker platform.\\n6. **DeepMind**: DeepMind, a subsidiary of Alphabet Inc., offers a range of LLMs, including AlphaBERT and AlphaFold, through their DeepMind platform.\\n7. **Meta AI**: Meta AI offers a range of LLMs, including BERT, RoBERTa, and OPT, through their Meta AI platform.\\n8. **Stanford Natural Language Processing Group**: The Stanford NLP Group offers a range of LLMs, including BERT, RoBERTa, and XLNet, through their GitHub repository.\\n9. **Allen Institute for Artificial Intelligence (AI2)**: AI2 offers a range of LLMs, including BERT, RoBERTa, and ULMFiT, through their GitHub repository.\\n10. **OpenAI**: OpenAI offers a range of LLMs, including GPT-3 and GPT-4, through their API.\\n\\nThese are just a few examples of model providers that offer LLMs. There are many other organizations and researchers that also offer LLMs, and the list is constantly growing.\\n\\nPlease note that some of these models may require a subscription or a one-time payment to access, and some may have usage limits or restrictions.', additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 29, 'total_tokens': 483, 'completion_tokens': 454}, 'model': 'Turbo', 'finish_reason': 'FinishReason.stop'}, id='run--afa76d87-6cb8-487a-bffd-3f14bdce7c1b-0', usage_metadata={'input_tokens': 29, 'output_tokens': 454, 'total_tokens': 483})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the building blocks\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'You are a helpful assistant.'),\n",
    "    ('human', '{question}'),\n",
    "])\n",
    "\n",
    "\n",
    "# combine them with the | operator\n",
    "\n",
    "chatbot = template | model\n",
    "\n",
    "# use it\n",
    "\n",
    "chatbot.invoke({\"question\": \"Which model providers offer LLMs?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning_langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
